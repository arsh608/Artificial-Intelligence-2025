**ASSIGNMENT 1**

Q1: 
**Alan Turing’s "Computing Machinery and Intelligence":**
Alan Turing wrote an important paper in 1950 called "Computing Machinery and Intelligence," laid the foundation for discussions on artificial intelligence (AI). Turing proposed the famous Imitation Game, now known as the Turing Test, to evaluate a machine’s ability to exhibit intelligent behaviour indistinguishable from that of a human. In his paper, he also discussed and responded to several objections people might have about machine intelligence. This essay examines which objections are still relevant, evaluates Turing’s refutations, considers new objections arising from technological advancements, and reflects on his prediction regarding AI’s ability to pass the Turing Test by the year 2000.

**Objections That Still Matter:**

Turing addressed multiple objections, including the theological objection, the mathematical objection, the argument from consciousness, and others. Some of these objections still hold relevance today:
1.	The Argument from Consciousness: Turing discussed the view that machines cannot possess consciousness, emotions, or subjective experience. This issue remains unresolved in modern AI discourse. Contemporary cognitive scientists and philosophers argue that even if machines exhibit intelligent behaviour, they may lack the qualia of human experience, a concern that remains significant in debates on artificial general intelligence (AGI).
2.	The Mathematical Objection: Based on Gödel’s incompleteness theorems, this objection proposes that there are mathematical truths machines cannot prove. While AI has advanced significantly in automated theorem proving, Gödel’s theorem still implies that certain problems remain undecidable, limiting the scope of machine intelligence.
3.	The Lady Lovelace Objection: Ada Lovelace argued that machines can only do what they are programmed to do and cannot originate new ideas. Although modern AI exhibits emergent behaviours, such as generative models creating novel text and art, these behaviours arise from variable patterns in existing data rather than true creativity or autonomous thought. Thus, this objection continues to hold some weight.

**Validity of Turing’s Responses:**

Turing disagreed with many objections to machine intelligence, but some of his arguments are still debated today:
1.	Against the Argument from Consciousness: Turing argued that a machine does not need consciousness to be considered intelligent. He believed that focusing on behaviour, rather than internal thoughts or feelings, was enough. Back in his time, behaviourism was a popular idea in psychology. However, modern cognitive science now recognizes the importance of internal states, making Turing’s argument less convincing.
2.	Against the Lady Lovelace Objection: Ada Lovelace suggested that machines can only do what they are programmed to do and cannot be truly creative. Turing responded by pointing out that machines can surprise us by learning and acting in ways we do not directly program. However, critics argue that even today’s most advanced AI systems do not have true independence or purpose; they still follow human-designed rules and goals.
3.	Against the Mathematical Objection: This argument is based on Gödel’s theorem, which suggests there are limits to what machines can compute. Turing acknowledged this but argued that humans also have limitations in reasoning. However, humans rely on intuition and insights that machines do not possess, so this objection still holds some weight.

**New Objections from Modern AI Advancements:**

Since Turing’s time, advancements in AI have led to new challenges that he did not anticipate:
1.	Bias and Ethical Issues: Today’s AI systems can inherit biases from the data they are trained on, leading to unfair or discriminatory outcomes. This has become a serious ethical concern, affecting areas like hiring, policing, and loan approvals. Turing did not discuss this issue, but it is now a major problem in AI development.
2.	Explainability and Trust: Many AI models, especially deep learning systems, work in ways that are difficult for humans to understand. This “black box” problem makes it hard to trust AI in important fields like medicine and finance. Turing did not predict this issue, but today, explainability is a key concern in AI research.
3.	The AI Control Problem: Advanced AI systems, especially those using reinforcement learning and neural networks, can sometimes behave in unexpected ways. Ensuring AI follows human values and does not act against our interests is a major challenge. Turing did not anticipate this issue, but it has become one of the biggest concerns in AI safety today.

**Was Turing’s Prediction About AI in 2000 Correct?**

Turing predicted that by the year 2000, a machine would have a 30% chance of passing a five-minute Turing Test with an unskilled interrogator. This turned out to be too optimistic. While early chatbots like ELIZA and Cleverbot could imitate human conversation to some degree, they were not truly intelligent and could not convincingly pass the test.
Today, AI models like GPT-4 and ChatGPT have come much closer to passing the Turing Test. They can hold conversations that sometimes seem very human-like. However, they still make mistakes, struggle with understanding long conversations, and often fail when talking to skilled interrogators. Although AI has improved a lot, a truly human-like AI has not yet been achieved.

Turing’s paper is still one of the most important works in AI philosophy. Many of his ideas remain relevant, and some of the objections he countered have weakened over time. However, new challenges—such as bias, explainability, and AI alignment—have emerged. While his prediction about the Turing Test was not fully met by 2000, AI is continuously evolving toward that goal. Turing’s work continues to shape discussions about machine intelligence and its role in society.

Q2:
1.	Playing table tennis (ping-pong).
* Partially possible. AI-powered robots can hit the ball and play against humans, but they struggle with quick reflexes, unpredictable shots, and advanced strategies.
2.	Playing bridge at a competitive level.
*	Possible. AI programs like “Wbridge5” can play bridge at a high level, but they lack the deep intuition and psychological tactics of expert human players.
3.	Writing a funny story.
*	Difficult. AI can generate jokes and humorous text, but humour depends on culture, emotions, and context, which AI does not fully understand. Most AI-generated humour feels repetitive or unnatural.
4.	Giving legal advice in a specialized area of law.
*	Partially possible. AI can analyse legal documents, research laws, and suggest legal arguments. However, it cannot replace human lawyers because law requires reasoning, ethical judgment, and understanding of unique cases.
5.	Discovering and proving a new mathematical theorem.
*	Possible. AI can assist in finding patterns and proving known theorems. Some AI systems have contributed to mathematical discoveries, but human intuition is still needed for creating entirely new theorems.
6.	Performing a surgical operation.
*	Partially possible. Robotic systems assist in surgeries with great precision. However, they need human surgeons to control them, and they cannot make independent medical decisions.
7.	Unloading any dishwasher in any home.
*	Not yet possible. AI struggles with recognizing different kitchen layouts, understanding how to handle fragile dishes, and adapting to unpredictable home environments.
8.	Constructing a building.
*	Partially possible. Robots can assist in construction, such as laying bricks or using 3D printing to build houses. However, humans are still needed for designing, planning, and handling unexpected construction challenges.


Q3:
**Domain:** Virtual Personal Assistant (e.g., Siri, Google Assistant, Alexa)
**Description:**
The agent is an AI virtual assistant that helps users with tasks like setting reminders, answering questions, playing music, and controlling smart home devices. It processes voice commands, searches the internet, and interacts with apps to provide useful responses.
*	Accessible: The assistant understands voice commands but may not always have full context or access to private information.
*	Deterministic: Responses depend on user input, internet availability, and changing data sources. (slightly deterministic)
*	Episodic: Some tasks are independent (e.g., setting an alarm), but others (like conversations) build on past interactions. (Rather sequential)
*	Static: User commands and information keep changing, requiring constant updates so dynamic.
*	Continuous: The assistant listens and responds in real-time.
A hybrid agent is most effective, because it can instantly respond to commands, Plans actions and adapts to user preferences and improves.

Q4:
1. An agent with partial information cannot be perfectly rational.
*False: An agent can still make the best decision based on available information and predictions. Example: A self-driving car in fog can slow down and use sensors to drive safely.
2. Some environments make pure reflex agents irrational.
*True: Reflex agents only react to the current situation without thinking ahead. Example: In chess, a reflex agent making moves without planning will lose.
3. Every agent cannot be rational in the same environment.
*False: Some agents make better decisions than others. Example: In a maze, an agent following an optimal path is rational, but a random-moving agent is not.
4. Agent program input is the same as agent function input.
*False: The agent program can use extra data like memory, while the agent function is just a rule for actions. Example: A chatbot's function maps input to responses, but the program also uses past chats.
5. Every agent function can be implemented by a machine.
*False: Some functions require infinite memory or are too complex to compute. Example: Predicting every future event perfectly is impossible.
6. A random agent can be rational in a deterministic environment.
*True: If the task allows random choices, a random agent can still succeed. Example: If an agent must flip a fair coin, random selection is correct.
7. An agent can be rational in two different environments.
*True: If the goal and strategy work in both environments, the agent remains rational. Example: A sorting algorithm is useful for both inventory and grading systems.
